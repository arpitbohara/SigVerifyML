{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu   # For finding the threshold for grayscale to binary conversion\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "genuine_image_paths = \"D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\real/\"\n",
    "forged_image_paths = \"D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\forged/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbgrey(img):\n",
    "    # Converts rgb to grayscale\n",
    "    greyimg = np.zeros((img.shape[0], img.shape[1]))\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[row])):\n",
    "            greyimg[row][col] = np.average(img[row][col])\n",
    "    return greyimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greybin(img):\n",
    "    # Converts grayscale to binary\n",
    "    blur_radius = 0.8\n",
    "    img = ndimage.gaussian_filter(img, blur_radius)  # to remove small components or noise\n",
    "#     img = ndimage.binary_erosion(img).astype(img.dtype)\n",
    "    thres = threshold_otsu(img)\n",
    "    binimg = img > thres\n",
    "    binimg = np.logical_not(binimg)\n",
    "    return binimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproc(path, img=None, display=True):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    if display:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    grey = rgbgrey(img) #rgb to grey\n",
    "    if display:\n",
    "        plt.imshow(grey, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    binimg = greybin(grey) #grey to binary\n",
    "    if display:\n",
    "        plt.imshow(binimg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    r, c = np.where(binimg==1)\n",
    "    # Now we will make a bounding box with the boundary as the position of pixels on extreme.\n",
    "    # Thus we will get a cropped image with only the signature part.\n",
    "    signimg = binimg[r.min(): r.max(), c.min(): c.max()]\n",
    "    if display:\n",
    "        plt.imshow(signimg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    return signimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ratio(img):\n",
    "    a = 0\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                a = a+1\n",
    "    total = img.shape[0] * img.shape[1]\n",
    "    return a/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Centroid(img):\n",
    "    numOfWhites = 0\n",
    "    a = np.array([0,0])\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                b = np.array([row,col])\n",
    "                a = np.add(a,b)\n",
    "                numOfWhites += 1\n",
    "    rowcols = np.array([img.shape[0], img.shape[1]])\n",
    "    centroid = a/numOfWhites\n",
    "    centroid = centroid/rowcols\n",
    "    return centroid[0], centroid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SkewKurtosis(img):\n",
    "    h,w = img.shape\n",
    "    x = range(w)  # cols value\n",
    "    y = range(h)  # rows value\n",
    "    #calculate projections along the x and y axes\n",
    "    xp = np.sum(img,axis=0)\n",
    "    yp = np.sum(img,axis=1)\n",
    "    #centroid\n",
    "    cx = np.sum(x*xp)/np.sum(xp)\n",
    "    cy = np.sum(y*yp)/np.sum(yp)\n",
    "    #standard deviation\n",
    "    x2 = (x-cx)**2\n",
    "    y2 = (y-cy)**2\n",
    "    sx = np.sqrt(np.sum(x2*xp)/np.sum(img))\n",
    "    sy = np.sqrt(np.sum(y2*yp)/np.sum(img))\n",
    "    \n",
    "    #skewness\n",
    "    x3 = (x-cx)**3\n",
    "    y3 = (y-cy)**3\n",
    "    skewx = np.sum(xp*x3)/(np.sum(img) * sx**3)\n",
    "    skewy = np.sum(yp*y3)/(np.sum(img) * sy**3)\n",
    "\n",
    "    #Kurtosis\n",
    "    x4 = (x-cx)**4\n",
    "    y4 = (y-cy)**4\n",
    "    # 3 is subtracted to calculate relative to the normal distribution\n",
    "    kurtx = np.sum(xp*x4)/(np.sum(img) * sx**4) - 3\n",
    "    kurty = np.sum(yp*y4)/(np.sum(img) * sy**4) - 3\n",
    "\n",
    "    return (skewx , skewy), (kurtx, kurty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EccentricitySolidity(img):\n",
    "    r = regionprops(img.astype(\"int8\"))\n",
    "    return r[0].eccentricity, r[0].solidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    img = preproc(path, display=display)\n",
    "    ratio = Ratio(img)\n",
    "    centroid = Centroid(img)\n",
    "    eccentricity, solidity = EccentricitySolidity(img)\n",
    "    skewness, kurtosis = SkewKurtosis(img)\n",
    "    retVal = (ratio, centroid, eccentricity, solidity, skewness, kurtosis)\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCSVFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    temp = getFeatures(path, display=display)\n",
    "    features = (temp[0], temp[1][0], temp[1][1], temp[2], temp[3], temp[4][0], temp[4][1], temp[5][0], temp[5][1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCSVFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    temp = getFeatures(path, display=display)\n",
    "    features = (temp[0], temp[1][0], temp[1][1], temp[2], temp[3], temp[4][0], temp[4][1], temp[5][0], temp[5][1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Saving the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeCSV():\n",
    "    if not(os.path.exists('D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\Features')):\n",
    "        os.mkdir('D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\Features')\n",
    "        print('New folder \"Features\" created')\n",
    "    if not(os.path.exists('D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\Features/Training')):\n",
    "        \n",
    "        ('D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\Features/Training')\n",
    "        print('New folder \"Features/Training\" created')\n",
    "    if not(os.path.exists('D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\Features/Testing')):\n",
    "        os.mkdir('D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\Features/Testing')\n",
    "        print('New folder \"Features/Testing\" created')\n",
    "    # genuine signatures path\n",
    "    gpath = genuine_image_paths\n",
    "    # forged signatures path\n",
    "    fpath = forged_image_paths\n",
    "    for person in range(1,15):\n",
    "        per = ('00'+str(person))[-3:]\n",
    "        print('Saving features for person id-',per)\n",
    "        \n",
    "        with open('D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\Features\\\\Training/training_'+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "            # Training set\n",
    "            for i in range(0,3):\n",
    "                source = os.path.join(gpath, per+per+'_00'+str(i)+'.png')\n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')\n",
    "            for i in range(0,3):\n",
    "                source = os.path.join(fpath, '021'+per+'_00'+str(i)+'.png')\n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')\n",
    "        \n",
    "        with open('D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\Features\\\\Testing/testing_'+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "            # Testing set\n",
    "            for i in range(3, 5):\n",
    "                source = os.path.join(gpath, per+per+'_00'+str(i)+'.png')\n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')\n",
    "            for i in range(3,5):\n",
    "                source = os.path.join(fpath, '021'+per+'_00'+str(i)+'.png')\n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features for person id- 001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features for person id- 002\n",
      "Saving features for person id- 003\n",
      "Saving features for person id- 004\n",
      "Saving features for person id- 005\n",
      "Saving features for person id- 006\n",
      "Saving features for person id- 007\n",
      "Saving features for person id- 008\n",
      "Saving features for person id- 009\n",
      "Saving features for person id- 010\n",
      "Saving features for person id- 011\n",
      "Saving features for person id- 012\n",
      "Saving features for person id- 013\n",
      "Saving features for person id- 014\n"
     ]
    }
   ],
   "source": [
    "makeCSV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing(path):\n",
    "    feature = getCSVFeatures(path)\n",
    "    if not(os.path.exists('D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\TestFeatures')):\n",
    "        os.mkdir('D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\TestFeatures')\n",
    "    with open('D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\TestFeatures/testcsv.csv', 'w') as handle:\n",
    "        handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y\\n')\n",
    "        handle.write(','.join(map(str, feature))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.49950442\n",
      "100 0.25014457\n",
      "200 0.03897914\n",
      "300 0.012035054\n",
      "400 0.008766011\n",
      "500 0.0073023583\n",
      "600 0.0062269294\n",
      "700 0.005366041\n",
      "800 0.0046718963\n",
      "900 0.0041053253\n",
      "1000 0.0036260597\n",
      "1100 0.003194349\n",
      "1200 0.0027749417\n",
      "1300 0.002347472\n",
      "1400 0.0019185739\n",
      "1500 0.0015121456\n",
      "1600 0.0011465218\n",
      "1700 0.00083421526\n",
      "1800 0.00058550766\n",
      "1900 0.00040345857\n",
      "2000 0.00028016084\n",
      "2100 0.00020099459\n",
      "2200 0.00014996163\n",
      "2300 0.00011684767\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train: 1.0\n",
      "Forged Image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_input = 9\n",
    "train_person_id = input(\"Enter person's id : \")\n",
    "test_image_path = input(\"Enter path of signature image : \")\n",
    "train_path = 'D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\Features\\\\Training/training_'+train_person_id+'.csv'\n",
    "testing(test_image_path)\n",
    "test_path = 'D:\\\\Arpit College\\\\FYP\\\\SignatureVerificationSystem\\\\Data\\\\TestFeatures/testcsv.csv'\n",
    "\n",
    "def readCSV(train_path, test_path, type2=False):\n",
    "    # Reading train data\n",
    "    df = pd.read_csv(train_path, usecols=range(n_input))\n",
    "    train_input = np.array(df.values)\n",
    "    train_input = train_input.astype(np.float32, copy=False)  # Converting input to float_32\n",
    "    df = pd.read_csv(train_path, usecols=(n_input,))\n",
    "    temp = [elem[0] for elem in df.values]\n",
    "    correct = np.array(temp)\n",
    "    corr_train = keras.utils.to_categorical(correct,2)      # Converting to one hot\n",
    "    # Reading test data\n",
    "    df = pd.read_csv(test_path, usecols=range(n_input))\n",
    "    test_input = np.array(df.values)\n",
    "    test_input = test_input.astype(np.float32, copy=False)\n",
    "    if not(type2):\n",
    "        df = pd.read_csv(test_path, usecols=range(n_input))\n",
    "        temp = [elem[0] for elem in df.values]\n",
    "        correct = np.array(temp)\n",
    "        corr_test = keras.utils.to_categorical(correct,2)      # Converting to one hot\n",
    "    if not(type2):\n",
    "        return train_input, corr_train, test_input, corr_test\n",
    "    else:\n",
    "        return train_input, corr_train, test_input\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# Parameters\n",
    "learning_rate = 0.0009\n",
    "training_epochs = 10000\n",
    "display_step = 1\n",
    "\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 7 # 1st layer number of neurons\n",
    "n_hidden_2 = 13 # 2nd layer number of neurons\n",
    "# n_hidden_3 = 13 # 3rd layer\n",
    "n_classes = 2 # no. of classes (genuine or forged)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], seed=1)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2],seed=2)),\n",
    "    # 'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3], seed=1)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes], seed=2))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1], seed=1)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2], seed=2)),\n",
    "    # 'b3': tf.Variable(tf.random_normal([n_hidden_3], seed=2)),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes], seed=1))\n",
    "}\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x):\n",
    "    layer_1 = tf.tanh((tf.matmul(x, weights['h1']) + biases['b1']))\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    out_layer = tf.tanh(tf.matmul(layer_2, weights['out']) + biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = multilayer_perceptron(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.squared_difference(logits, Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# For accuracies\n",
    "pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "def evaluate(train_path, test_path, type2=False):   \n",
    "    if not(type2):\n",
    "        train_input, corr_train, test_input, corr_test = readCSV(train_path, test_path)\n",
    "    else:\n",
    "        train_input, corr_train, test_input = readCSV(train_path, test_path, type2)\n",
    "    ans = 'Random'\n",
    "    costs=[]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs):\n",
    "\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, cost = sess.run([train_op, loss_op], feed_dict={X: train_input, Y: corr_train})\n",
    "            costs.append(cost)\n",
    "\n",
    "            # if epoch==training_epochs-1:\n",
    "            #     print (epoch , cost)\n",
    "\n",
    "            if epoch%100==0:\n",
    "                print(epoch , cost)\n",
    "            elif epoch==training_epochs-1:\n",
    "                print(epoch , cost)\n",
    "\n",
    "            if cost<0.0001:\n",
    "                break\n",
    "#             # Display logs per epoch step\n",
    "        #     if epoch % 999 == 0:\n",
    "        #         print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(cost))\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "         # Plot the cost values\n",
    "        plt.plot(costs)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Cost')\n",
    "        plt.title('Cost vs. Epoch')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        # Finding accuracies\n",
    "        accuracy1 =  accuracy.eval({X: train_input, Y: corr_train})\n",
    "        print(\"Accuracy for train:\", accuracy1)\n",
    "        \n",
    "        if type2 is False:\n",
    "            accuracy2 =  accuracy.eval({X: test_input, Y: corr_test})   \n",
    "            print(\"Accuracy for test:\", accuracy2)\n",
    "\n",
    "            return accuracy1, accuracy2\n",
    "            \n",
    "        else:\n",
    "            prediction = pred.eval({X: test_input})\n",
    "            if prediction[0][1]>prediction[0][0]:\n",
    "                print('Genuine Image')\n",
    "                return True\n",
    "            else:\n",
    "                print('Forged Image')\n",
    "                return False\n",
    "\n",
    "\n",
    "def trainAndTest(rate=0.0009, epochs=10000, neurons=7, display=False):    \n",
    "    start = time()\n",
    "\n",
    "    # Parameters\n",
    "    global training_rate, training_epochs, n_hidden_1\n",
    "    learning_rate = rate\n",
    "    training_epochs = epochs\n",
    "\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = neurons # 1st layer number of neurons\n",
    "    n_hidden_2 = 13 # 2nd layer number of neurons\n",
    "\n",
    "    train_avg, test_avg = 0, 0\n",
    "    n = 14\n",
    "    for i in range(1,n+1):\n",
    "        if display:\n",
    "            print(\"Running for Person id\",i)\n",
    "        temp = ('0'+str(i))[-2:]\n",
    "        train_score, test_score = evaluate(train_path.replace('01',temp), test_path.replace('01',temp))\n",
    "        train_avg += train_score\n",
    "        test_avg += test_score\n",
    "    if display:\n",
    "        print(\"Number of neurons in Hidden layer-\", n_hidden_1)\n",
    "        print(\"Number of neurons in Hidden layer-\", n_hidden_2)\n",
    "        print(\"Training average-\", train_avg/n)\n",
    "        print(\"Testing average-\", test_avg/n)\n",
    "        print(\"Time taken-\", time()-start)\n",
    "        print(\"Learning rate- \", learning_rate)\n",
    "    return train_avg/n, test_avg/n, (time()-start)/n\n",
    "\n",
    "# trainAndTest(display=True)\n",
    "\n",
    "\n",
    "evaluate(train_path, test_path, type2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
